{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy training flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word     label\n",
      "0    happy  positive\n",
      "1      joy  positive\n",
      "2     love  positive\n",
      "3      sad  negative\n",
      "4    angry  negative\n",
      "5     hate  negative\n",
      "6  excited  positive\n",
      "7    bored  negative\n",
      "8  delight  positive\n",
      "9     fear  negative\n"
     ]
    }
   ],
   "source": [
    "# Creamos un dataset simple con palabras etiquetadas como positivas o negativas\n",
    "data = {'word': ['happy', 'joy', 'love', 'sad', 'angry', 'hate', 'excited', 'bored', 'delight', 'fear'],\n",
    "        'label': ['positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/david/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data] Downloading package punkt to /home/david/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.845\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.83      0.85       206\n",
      "         pos       0.83      0.86      0.84       194\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.85      0.85      0.84       400\n",
      "weighted avg       0.85      0.84      0.85       400\n",
      "\n",
      "Review: 'The movie was fantastic and had a great plot.' => Sentiment: pos\n",
      "Review: 'I really hated the film, it was too boring and slow.' => Sentiment: neg\n",
      "Review: 'The acting was mediocre but the story was excellent.' => Sentiment: pos\n",
      "Review: 'One of the worst movies I have ever seen.' => Sentiment: neg\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "\n",
    "# Descargar el corpus de nltk (si es la primera vez que lo usas)\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 1. Cargar el dataset de IMDb desde NLTK\n",
    "# El dataset de NLTK contiene reseñas de películas etiquetadas como 'pos' (positivo) o 'neg' (negativo)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Barajar el dataset para que no haya sesgo de orden\n",
    "random.shuffle(documents)\n",
    "\n",
    "# Convertir las reseñas de listas de palabras a frases\n",
    "reviews = [\" \".join(words) for words, category in documents]\n",
    "sentiments = [category for words, category in documents]\n",
    "\n",
    "# Crear un DataFrame para facilitar el manejo\n",
    "df = pd.DataFrame({'review': reviews, 'sentiment': sentiments})\n",
    "\n",
    "# 2. Preprocesar el texto\n",
    "# Convertimos las frases en vectores numéricos usando TF-IDF (mejor que Bag of Words para frases)\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)  # Usamos las 5000 palabras más comunes\n",
    "X = vectorizer.fit_transform(df['review'])  # X son las características (las reseñas vectorizadas)\n",
    "y = df['sentiment']  # y es la variable objetivo (etiquetas de sentimientos)\n",
    "\n",
    "# 3. Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Entrenar el modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluar el modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# 6. Hacer predicciones con frases nuevas\n",
    "new_reviews = [\n",
    "    \"The movie was fantastic and had a great plot.\",\n",
    "    \"I really hated the film, it was too boring and slow.\",\n",
    "    \"The acting was mediocre but the story was excellent.\",\n",
    "    \"One of the worst movies I have ever seen.\"\n",
    "]\n",
    "\n",
    "# Convertimos las nuevas frases a su representación numérica\n",
    "X_new = vectorizer.transform(new_reviews)\n",
    "\n",
    "# Hacemos predicciones\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Mostramos las predicciones\n",
    "for review, prediction in zip(new_reviews, predictions):\n",
    "    print(f\"Review: '{review}' => Sentiment: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42800558, 0.57199442],\n",
       "       [0.60284464, 0.39715536],\n",
       "       [0.43861451, 0.56138549],\n",
       "       [0.65080868, 0.34919132]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'neg', 'pos', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo en un archivo local usando joblib\n",
    "joblib.dump(model, 'model.pkl')  # Guardamos el modelo\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')  # Guardamos también el vectorizador"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
